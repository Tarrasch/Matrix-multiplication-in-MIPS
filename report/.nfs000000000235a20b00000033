\documentclass[a4paper,11pt]{article}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage{lmodern}
\usepackage{hyperref}
\usepackage{graphicx}
\usepackage{rotating}
\usepackage{listings}
\usepackage{color}
\usepackage{mips}


\definecolor{dkgreen}{rgb}{0,0.6,0}
\definecolor{gray}{rgb}{0.5,0.5,0.5}
\definecolor{mauve}{rgb}{0.58,0,0.82}

\lstset{frame=tb,
  language=[mips]Assembler,
  aboveskip=3mm,
  belowskip=3mm,
  showstringspaces=false,
  columns=flexible,
  basicstyle={\small\ttfamily},
  numbers=none,
  numberstyle=\tiny\color{gray},
  keywordstyle=\color{blue},
  commentstyle=\color{dkgreen},
  stringstyle=\color{mauve},
  breaklines=true,
  breakatwhitespace=true
  tabsize=3
}

\title{Monetarily efficient Gauss Elimination}
\author{Arash Rouhani and Jonas Ängeslevä}

\begin{document}

\maketitle

\section{Computer System}
We have written a gauss elimination program for MIPS assembler, the program is optimized for the hardware. Details below.
\subsection{hardware}
The MIPS processor have 5 pipe lines stages, seperate I and D cache, a write buffer and two coprocessors.
The caches can be in sizes of 128, 256 and 512 bytes, and are using LRU replacement policy and Write Back replacement policy.
The Least Recently Used is a replacement policy, where the element in the set that was least recently used is replaced, if the cache is full. Note that this only maters in N-way caches (where N>1).
The Write Back writing policy means that when writing to the memory, we don't actually write to the memory if the memory is cached. 
\subsection{software}
The algorithm used for the elimination is the one suggested.
Only some minor optimizations have been at an algorithmical level. We do not unncessisarily loop at the last row (it's always 0 0 ... 0 0 1).
This assumption makes our code to actually only work on invertable matrices.

For optimization, the code does use delayed branching slots, does not do indexing or call any subroutines. 
Furthermore it does not violate the MIPS conventions for subroutines, it however mutates a0, so the test program must be corrected accordingly.


\section{Configurations}
There are many ways to configure the hardware. We have experimentally tested and tabled some experiments, the parameters have been chosen to gradually try to increase the price*performence value, that is, we have used a \emph{greedily optimizing} method for parameter refining.

Changing the parameters sometimes give a significant effect, and sometimes it doesn't. If we look at the table, it's very clear that:
\begin{itemize}
\item An expensive I cache makes little difference.
\item 2-way associativity is superior. It outperforms 4 also in clock cycles.
\item Buffer size 1 is as fast as size 8 measured in clock cycles, but 1 is faster than 0.
\item The expensive memory outperforms the cheaper one from a price*performance standpoint.
In the rest of this subchapter we'll explain why we observe these extremities.
\end{itemize}
The I cache don't need to be big because the instructions are all close together, the whole content of the outermost loop definetly fits in 32 words, and we don't call subroutines, so the program pointer never leaves that scope.

One way associativity is bad because it doesn't play well with the data access patter.
See the Figure 4 in the assignment paper, there the (1) and (3) data accessor are rapidly sweeping lines.
(1) is sweeping the same line over and over again, we don't want (3) to throw out anything cached on the line where (1) is sweeping.
This is where two-way comes in, the competition for chache memory placement is decreased as two spots are available for every memory location.
Four way associativity however is to overhouse for the only 2 active sweepers.
Four-way associativity costs however, because searching in the cache must visit 4 locations, increasing delays.

A write buffer is not having a signifcant impacts, even though we do $O(n^3)$ writes.
Most writes are directly to cache memory rather than misses, so writing to real memory is often avoided, thus the need for a buffer decreased.

Reading from real memory however happens often, and that is why the expensive memory pays off.
This raises the question why it doesn't help to have a write buffer if memory interaction is common.
The reason is that most writes are to a memory location we've just read from, and therfor it is cached already.
\subsection{Best configuration}
The best condfiguration for I-cache uses 8 word block size, has 4 blocks and uses direct-mapping.
The D-cache uses 2-way mapping, has a block size of 8 words and 8 blocks. Withy these hardware choices the elimination takes only
72469 cycles and costs 2415.63 \µSC\$.

%\includegraphics[width=210mm,height=297mm,angle=270]{table.png}  
\begin{center}
\includegraphics[width=200mm,angle=270]{table.png}
\end{center}
\section{Appendix}
\subsection{Code}
\begin{lstlisting}
################################################################################
# eliminate - Triangularize matrix.
#
# Args:		$a0  - base address of matrix (A)
#			$a1  - number of elements per row (N)

eliminate:
		# let t7 = n*4, 
		# number of bytes we must jump ahead to get to next line
		sll		$t7, $a1, 2
	
		# We first initiate some variables,
		# we want t0 to be A+4*n*n
		mul		$t0, $a1, $a1
		sll 	$t0, $t0, 2
		add		$t0, $a0, $t0
		sub 	$t0, $t0, $t7
		sub 	$t4, $t0, $t7 # Let t4 be the position we should stop at
		sub 	$t0, $t0, $t7 # test temp


		l.s		$f0, constant_zero	# Let f0 be a constant 0.0
		l.s		$f1, constant_one	# Let f1 be a constant 1.0
		addi	$t8, $a0, 0			# t8 = Position for diagonal element
		addi	$t9, $a1, 1			# t9 = number of steps to jump
		sll		$t9, $t9, 2			# t9 *= 4, to correctify
		
		# We do so a0 is the "line after" the current line
		add		$a0, $a0, $t7		# a0+=4*n, this is important for loop to terminate
loop_outermost:
		
		# We want to do $f2 = 1/A[k][k], for that we need:
		#	1. get the value A[k][k] to f2
		#	2. $f2 = 1/$f2
		l.s		$f2, ($t8)			# f2 = A[k][k]
		div.s	$f2, $f1, $f2		# f2 = 1/f2
		
		# We want to do A[k][j] = A[k][j] * inv, for i = k+1 .. N-1
		#	1. Loop with t1=j, starting with j = k+1
		#		practicaly this is $t1 = diag+1 = $t8+1
		#	2. ($t1) = ($t1)*inv = ($t1)*$f2
		#		practically first lw $t1 then sw later
		#	3. stop loop
		#		practically when $t1 = $a0
		addi	$t1, $t8, 4			# t1 = diag+1word
		l.s		$f3, ($t1)			# f2   <-- [t1]		
loop_pivot_row_dividing:
		mul.s	$f3, $f3, $f2		# f2   <-- f2 * inv
		s.s		$f3, ($t1)			# [t1] <-- f2
		addi	$t1, $t1,	4		# t1   <-- t1 + 4 
		bne 	$a0, $t1,	loop_pivot_row_dividing # loop if not finished
		l.s		$f3, ($t1)			# f2   <-- [t1]


		# We want to do big loop
		#	1. In preperation we set t1 to be our ROW-looper
		#	2. In the outer loop we extract the leftelement, that is $f2=[t1]
		#		We also initialize the column-looper t2 and body-looper t3
		#		This loop terminates when $t1 HAVE BEEN t0, remember t0 is a line above last!!!!
		#	3. In the body we must increment t2 and t3.
		#		use $f3=[t2] and $f4=[t3]. Use $f5=$f2*$f3 as intermediete for $f4-=$f5
		#		Terminates when t2 reaches a0
		#	3. When Inner loop is terminated, we must set [t1] = 0.0
		#		practically when $t1 = $a0
		add		$t1, $t8, $t7		# t1   <-- diag+n*4
outer_big_loop:
		l.s		$f2, ($t1)			# f2   <-- [t1]
		addi	$t2, $t8, 4			# t2   <-- diag+4
		addi	$t3, $t1, 4			# t3   <-- t1+4
inner_big_loop:
		l.s		$f3, ($t2)			# f3   <-- [t2]
		l.s		$f4, ($t3)			# f4   <-- [t3]
		mul.s	$f5, $f2, $f3		# f5   <-- f2*f3
		sub.s	$f4, $f4, $f5		# f4   <-- f4-f5
		s.s		$f4, ($t3)			# [t3] <-- f4
		addi	$t2, $t2, 4			# t2   <-- t2 + 4
		bne		$t\begin{lstlisting}2, $a0, inner_big_loop	# loopa
		addi	$t3, $t3, 4			# t3   <-- t3 + 4

		s.s		$f0, ($t1)			# [t1] <-- zero
		bne		$t1, $t4, outer_big_loop	# loop
		add		$t1, $t1, $t7		# t1   <-- t1 + n*4 	# important for loop logic

		#### END INNER BIG LOOP
		
		# Pre-outerloop updates
		s.s		$f1, ($t8)			# set [diag]=1 
		add		$t8, $t8, $t9		# diag+=n+1; where t8 is diag and t9 is n+1		
		addi	$t4, $t4, 4			# t4 = next square, that is where big-loop should end at
		bne		$a0, $t0, loop_outermost		# jump back to outermost loop
		add		$a0, $a0, $t7		# a0+=4*n, this is important for loop to terminate

		#### END OUTERMOST LOOP

		# First we just fix A[n-1][n]
		addi	$t1, $t8, 4			# t1       <-- diag+4, this is also user later!
		l.s		$f2, ($t8)			# f2       <-- [diag]		
		l.s		$f3, ($t1)			# f3       <-- [t1]
		div.s	$f3, $f3, $f2		# f3       <-- f3/f2		
		s.s		$f3, ($t1)			# [t1]     <-- f3
		s.s		$f1, ($t8)			# set [diag]=1, for the second last time

		# Now lets fix last row, lets loop with t1
		add		$t8, $t8, $t9		# diag+=n+1; where t8 is diag and t9 is n+1				
loop_final_row:
		addi	$t1, $t1, 4			# t1       <-- t1+4
		bne		$t1, $t8, loop_final_row   # loop unless reached last diag ([n][n])
		s.s		$f0, ($t1)			# [t1]	   <-- 0

		# Now lets finally set [n][n]
		s.s		$f1, ($t8)			# set [diag]=1, for the last time


		# END OF ELIMINATION, ABOUT TO RETURN

		jr		$ra					# return from subroutine
		nop							# this is the delay slot associated with all types of jumps

\end{lstlisting}
\end{document}

